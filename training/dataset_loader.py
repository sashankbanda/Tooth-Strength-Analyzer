
import os
import torch
import cv2
import numpy as np
from torch.utils.data import Dataset
from pycocotools.coco import COCO
from PIL import Image

class ToothDetectionDataset(Dataset):
    """
    Dataset for Tooth Detection (Mask R-CNN)
    Expects labels in COCO format (generated by CVAT/Roboflow).
    """
    def __init__(self, root_dir, annotation_file, transforms=None):
        self.root_dir = root_dir
        self.coco = COCO(annotation_file)
        self.ids = list(sorted(self.coco.imgs.keys()))
        self.transforms = transforms

    def __getitem__(self, index):
        # Load image
        coco = self.coco
        img_id = self.ids[index]
        ann_ids = coco.getAnnIds(imgIds=img_id)
        coco_annotation = coco.loadAnns(ann_ids)
        
        path = coco.loadImgs(img_id)[0]['file_name']
        img_path = os.path.join(self.root_dir, path)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Count objects
        num_objs = len(coco_annotation)

        # Bounding boxes
        boxes = []
        for i in range(num_objs):
            xmin = coco_annotation[i]['bbox'][0]
            ymin = coco_annotation[i]['bbox'][1]
            xmax = xmin + coco_annotation[i]['bbox'][2]
            ymax = ymin + coco_annotation[i]['bbox'][3]
            boxes.append([xmin, ymin, xmax, ymax])

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        
        # Labels (Assuming only 1 class: Tooth)
        labels = torch.ones((num_objs,), dtype=torch.int64)
        
        # Masks (if instance segmentation)
        # For simple detection, we might not strictly need masks here unless we train Mask R-CNN fully
        # To keep it simple, let's assume valid COCO polygons provided
        masks = []
        for i in range(num_objs):
             mask = coco.annToMask(coco_annotation[i])
             masks.append(mask)
             
        if num_objs > 0:
            masks = np.stack(masks, axis=0)
        else:
            # Handle empty case
            masks = np.zeros((0, img.shape[0], img.shape[1]), dtype=np.uint8)
            
        masks = torch.as_tensor(masks, dtype=torch.uint8)

        image_id = torch.tensor([img_id])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)

        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        target["masks"] = masks
        target["image_id"] = image_id
        target["area"] = area
        target["iscrowd"] = iscrowd

        if self.transforms is not None:
            img, target = self.transforms(img, target)

        return img, target

    def __len__(self):
        return len(self.ids)


class ToothStructureDataset(Dataset):
    """
    Dataset for Structure Segmentation (U-Net++)
    Expects Image + Mask (where mask has classes: 0=BG, 1=Root, 2=Bone)
    """
    def __init__(self, images_dir, masks_dir, transforms=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.transforms = transforms
        self.ids = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, i):
        img_name = self.ids[i]
        img_path = os.path.join(self.images_dir, img_name)
        mask_path = os.path.join(self.masks_dir, img_name) # Assuming same name

        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        mask = cv2.imread(mask_path, 0) # Read as grayscale
        # Ensure mask is not None
        if mask is None:
             # Create dummy mask if missing
             mask = np.zeros(image.shape[:2], dtype=np.uint8)

        # Preprocessing/Transforms would go here
        
        # Convert to tensor
        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
        mask = torch.from_numpy(mask).long()

        return image, mask
